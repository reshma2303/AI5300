{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c70fae2",
   "metadata": {},
   "source": [
    "## Phase - 2: Predicting Anomalies in Network Traffic (A Binary Classification problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef65168",
   "metadata": {},
   "source": [
    "Before working on this phase, please practice \"Activities 4, 5, and 6\" in the 'Neural networks using Tensorflow' crash course (see nn-tf tab). \n",
    "\n",
    "The main goal in this phase is to experiment and find what network size is needed to 'overfit' the entire dataset at your hand.\n",
    "\n",
    "In other words, we want to determine how big architecture we need to overfit the data. \n",
    "\n",
    "     The place to start is to use 'logistic regression' model and train for as many epochs as needed to obtain as high accuracy as possible. After training hundreds of epochs if you observe that the accuracy is not increasing then it implies that the number of neurons in your model (only one) may not be sufficient for overfitting. \n",
    "      The next step is to grow your model into a multi-layer model and add a few neurons (say only 2) in the input layer. This way your model will have '2 + 1 = 3' neurons in total. \n",
    "       \n",
    "       If your accuracy still does not each a 100% or close to 100% you can continue to increase the number of layers and number of neurons. Once you have obtained 100% accuracy (or around 100%) your experiments for this phase are complete. The results of this experiment also inform us that our final model (in subsequent phases) should be smaller than this model. Small here refers to number of layers and number of neurons in each layer.\n",
    "\n",
    "[BONUS] You will be eligible to receive up to 2 bonus points if you complete this phase without using the Keras/Tenforflow library, i.e., if you implement your own Python code to build neural network (or logistic regression model) and code a function that serves as an optimizer (for example, gradient descent algorithm) to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec0a85",
   "metadata": {},
   "source": [
    "'protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f323bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catg_cols = ['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856cbab",
   "metadata": {},
   "source": [
    "#### 2.2 Continuous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "eb50db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [ 'duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abccd61",
   "metadata": {},
   "source": [
    "#### 2.3 Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b434d3",
   "metadata": {},
   "source": [
    "The target variable \"label\" contains all different types of malware attacks and also the value \"normal\" (i.e., not an attack) as shown below.\n",
    "\n",
    "'normal', 'buffer_overflow', 'loadmodule', 'perl', 'neptune', 'smurf', 'guess_passwd', 'pod', 'teardrop', 'portsweep', 'ipsweep', 'land', 'ftp_write', 'back', 'imap', 'satan', 'phf', 'nmap', 'multihop', 'warezmaster', 'warezclient', 'spy', 'rootkit'\n",
    "\n",
    "All malware attacks are grouped (transformed) to the value \"abnormal\" to make this problem a binary classification problem instead of a multi-class classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3986fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccae6cd",
   "metadata": {},
   "source": [
    "#### 2.4 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "36e844e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../datasets/kddcup99_csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c8f74",
   "metadata": {},
   "source": [
    "#### 2.5 Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3059174e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac162b93",
   "metadata": {},
   "source": [
    "494020 records with 41 features and 1 target variable (\"label\") for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95f9b3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                   9   \n",
       "1               0       0    0  ...                  19   \n",
       "2               0       0    0  ...                  29   \n",
       "3               0       0    0  ...                  39   \n",
       "4               0       0    0  ...                  49   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                          0.0   \n",
       "1                         0.05                          0.0   \n",
       "2                         0.03                          0.0   \n",
       "3                         0.03                          0.0   \n",
       "4                         0.02                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate   label  \n",
       "0                       0.0  normal  \n",
       "1                       0.0  normal  \n",
       "2                       0.0  normal  \n",
       "3                       0.0  normal  \n",
       "4                       0.0  normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6d066",
   "metadata": {},
   "source": [
    "As seen above, there are various type of malware attacks which can be grouped as \"abnormal\" to make this problem as binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32104edd",
   "metadata": {},
   "source": [
    "##### 2.6.1 Group all malware attacks as \"abnormal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c866ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types = list(df['label'].unique())\n",
    "attack_types.remove('normal') # remove normal from attack types as we only want malware attacks to convert as abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "90dc8e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].replace(attack_types, 'abnormal')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e77267f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abnormal    396743\n",
       "normal       97277\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "39174e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol_type     object\n",
       "service           object\n",
       "flag              object\n",
       "land               int64\n",
       "logged_in          int64\n",
       "is_host_login      int64\n",
       "is_guest_login     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[catg_cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe945967",
   "metadata": {},
   "source": [
    "As seen from the above datatypes of the categorical columns,the column values are not strings. We need to convert them to string before performing any analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32474eda",
   "metadata": {},
   "source": [
    "##### 2.7.1 Fixing the data types of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ad980c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol_type     object\n",
       "service           object\n",
       "flag              object\n",
       "land              object\n",
       "logged_in         object\n",
       "is_host_login     object\n",
       "is_guest_login    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['protocol_type'] = df['protocol_type'].astype(str)\n",
    "df['service'] = df['service'].astype(str)\n",
    "df['flag'] = df['flag'].astype(str)\n",
    "df['land'] = df['land'].astype(str)\n",
    "df['logged_in'] = df['logged_in'].astype(str)\n",
    "df['is_host_login'] = df['is_host_login'].astype(str)\n",
    "df['is_guest_login'] = df['is_guest_login'].astype(str)\n",
    "df[catg_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7f522dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['is_host_login'], inplace=True)\n",
    "df.drop(columns=['num_outbound_cmds'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc893c2",
   "metadata": {},
   "source": [
    "### 3. Transform Target Binary label to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "395e1caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    396743\n",
       "1     97277\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'normal': 1, 'abnormal': 0})\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e246b98",
   "metadata": {},
   "source": [
    "### 3. One hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be8e7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_to_one_hot_encoding(dataset, column_name):\n",
    "    dummy_values = pd.get_dummies(dataset[column_name])\n",
    "    \n",
    "    for category in dummy_values.columns:\n",
    "        dummy_value_name = f\"{column_name}-{category}\"\n",
    "        dataset[dummy_value_name] = dummy_values[category]\n",
    "    dataset.drop(column_name, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1854b7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 120)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat_col in catg_cols:\n",
    "    if cat_col != \"is_host_login\":\n",
    "        convert_categorical_to_one_hot_encoding(df, cat_col)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d0ebdcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag-S2</th>\n",
       "      <th>flag-S3</th>\n",
       "      <th>flag-SF</th>\n",
       "      <th>flag-SH</th>\n",
       "      <th>land-0</th>\n",
       "      <th>land-1</th>\n",
       "      <th>logged_in-0</th>\n",
       "      <th>logged_in-1</th>\n",
       "      <th>is_guest_login-0</th>\n",
       "      <th>is_guest_login-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  wrong_fragment  urgent  hot  \\\n",
       "0         0        181       5450               0       0    0   \n",
       "1         0        239        486               0       0    0   \n",
       "2         0        235       1337               0       0    0   \n",
       "3         0        219       1337               0       0    0   \n",
       "4         0        217       2032               0       0    0   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  ...  flag-S2  \\\n",
       "0                  0                0           0             0  ...        0   \n",
       "1                  0                0           0             0  ...        0   \n",
       "2                  0                0           0             0  ...        0   \n",
       "3                  0                0           0             0  ...        0   \n",
       "4                  0                0           0             0  ...        0   \n",
       "\n",
       "   flag-S3  flag-SF  flag-SH  land-0  land-1  logged_in-0  logged_in-1  \\\n",
       "0        0        1        0       1       0            0            1   \n",
       "1        0        1        0       1       0            0            1   \n",
       "2        0        1        0       1       0            0            1   \n",
       "3        0        1        0       1       0            0            1   \n",
       "4        0        1        0       1       0            0            1   \n",
       "\n",
       "   is_guest_login-0  is_guest_login-1  \n",
       "0                 1                 0  \n",
       "1                 1                 0  \n",
       "2                 1                 0  \n",
       "3                 1                 0  \n",
       "4                 1                 0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ded3a",
   "metadata": {},
   "source": [
    "###### a. Shuffle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a7b2faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d59f3",
   "metadata": {},
   "source": [
    "### 3. Data Normalization (scaling numerical features to unit norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c05167",
   "metadata": {},
   "source": [
    "As seen from the above continous variables distribution in the section 2.6 the scale of some of the features (columns) values are not in same range as others.\n",
    "Hence the features need to be normalized so that the optimization during model training will happen in a better way and the model will not be sensitive to the features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f502ede",
   "metadata": {},
   "source": [
    "# Using Min-max normalization\n",
    "min = X.min(axis = 0) \n",
    "max = X.max(axis = 0) \n",
    "X = (X - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "78a71197",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols_new = [each for each in cont_cols if each!='num_outbound_cmds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "42e2b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CONTCOLS_MIN = df[cont_cols_new].min(axis=0)\n",
    "df_CONTCOLS_MAX = df[cont_cols_new].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5317830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cont_cols_new] = (df[cont_cols_new] - df_CONTCOLS_MIN) / (df_CONTCOLS_MAX - df_CONTCOLS_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "0c369d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078431</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.488371e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.855595e-07</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121569</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.296593</td>\n",
       "      <td>2.105641e-07</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.488371e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration     src_bytes  dst_bytes  wrong_fragment  urgent  hot  \\\n",
       "0  0.000000  0.000000e+00   0.000000             0.0     0.0  0.0   \n",
       "1  0.000000  1.488371e-06   0.000000             0.0     0.0  0.0   \n",
       "2  0.000000  2.855595e-07   0.000125             0.0     0.0  0.0   \n",
       "3  0.296593  2.105641e-07   0.000020             0.0     0.0  0.0   \n",
       "4  0.000000  1.488371e-06   0.000000             0.0     0.0  0.0   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  ...  \\\n",
       "0                0.0              0.0         0.0           0.0  ...   \n",
       "1                0.0              0.0         0.0           0.0  ...   \n",
       "2                0.0              0.0         0.0           0.0  ...   \n",
       "3                0.0              0.0         0.0           0.0  ...   \n",
       "4                0.0              0.0         0.0           0.0  ...   \n",
       "\n",
       "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0        1.000000            0.078431                    0.08   \n",
       "1        1.000000            1.000000                    1.00   \n",
       "2        0.121569            1.000000                    1.00   \n",
       "3        1.000000            0.003922                    0.00   \n",
       "4        1.000000            1.000000                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.07                         0.00   \n",
       "1                    0.00                         1.00   \n",
       "2                    0.00                         0.03   \n",
       "3                    0.67                         0.98   \n",
       "4                    0.00                         1.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                   0.0   \n",
       "1                         0.00                   0.0   \n",
       "2                         0.07                   0.0   \n",
       "3                         0.00                   0.0   \n",
       "4                         0.00                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                       0.0                   1.0                       1.0  \n",
       "1                       0.0                   0.0                       0.0  \n",
       "2                       0.0                   0.0                       0.0  \n",
       "3                       0.0                   0.0                       0.0  \n",
       "4                       0.0                   0.0                       0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cont_cols_new].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "bf675cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "266522b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_numpy = XTRAIN.to_numpy()\n",
    "y_train_numpy = YTRAIN.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5e451662",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = df.drop(columns=['label']).to_numpy()\n",
    "Y_numpy = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "679e0d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 119)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "fb696424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6428c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim = len(X_numpy[0, :]), activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e967cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0540 - accuracy: 0.9816\n",
      "Epoch 2/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0283 - accuracy: 0.9915\n",
      "Epoch 3/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0255 - accuracy: 0.9915\n",
      "Epoch 4/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0240 - accuracy: 0.9915\n",
      "Epoch 5/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0230 - accuracy: 0.9915\n",
      "Epoch 6/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0225 - accuracy: 0.9915\n",
      "Epoch 7/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0219 - accuracy: 0.9915\n",
      "Epoch 8/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0216 - accuracy: 0.9916\n",
      "Epoch 9/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0211 - accuracy: 0.9917\n",
      "Epoch 10/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0210 - accuracy: 0.9918\n",
      "Epoch 11/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0207 - accuracy: 0.9921\n",
      "Epoch 12/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0203 - accuracy: 0.9923\n",
      "Epoch 13/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0202 - accuracy: 0.9925\n",
      "Epoch 14/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0201 - accuracy: 0.9926\n",
      "Epoch 15/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0198 - accuracy: 0.9928\n",
      "Epoch 16/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0198 - accuracy: 0.9929\n",
      "Epoch 17/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0196 - accuracy: 0.9930\n",
      "Epoch 18/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0194 - accuracy: 0.9932\n",
      "Epoch 19/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0194 - accuracy: 0.9933\n",
      "Epoch 20/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0193 - accuracy: 0.9933\n",
      "Epoch 21/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0191 - accuracy: 0.9934\n",
      "Epoch 22/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0190 - accuracy: 0.9934\n",
      "Epoch 23/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0189 - accuracy: 0.9935\n",
      "Epoch 24/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9937\n",
      "Epoch 25/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9939\n",
      "Epoch 26/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0188 - accuracy: 0.9945\n",
      "Epoch 27/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0188 - accuracy: 0.9947\n",
      "Epoch 28/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0188 - accuracy: 0.9954\n",
      "Epoch 29/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9960\n",
      "Epoch 30/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0188 - accuracy: 0.9960\n",
      "Epoch 31/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9967\n",
      "Epoch 32/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9968\n",
      "Epoch 33/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0188 - accuracy: 0.9969\n",
      "Epoch 34/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0188 - accuracy: 0.9969\n",
      "Epoch 35/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0188 - accuracy: 0.9969\n",
      "Epoch 36/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9969\n",
      "Epoch 37/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0189 - accuracy: 0.9969\n",
      "Epoch 38/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0190 - accuracy: 0.9970\n",
      "Epoch 39/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0190 - accuracy: 0.9970\n",
      "Epoch 40/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0191 - accuracy: 0.9970\n",
      "Epoch 41/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0191 - accuracy: 0.9970\n",
      "Epoch 42/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0190 - accuracy: 0.9971\n",
      "Epoch 43/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0191 - accuracy: 0.9971\n",
      "Epoch 44/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0191 - accuracy: 0.9972\n",
      "Epoch 45/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0191 - accuracy: 0.9972\n",
      "Epoch 46/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0192 - accuracy: 0.9973\n",
      "Epoch 47/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0192 - accuracy: 0.9973\n",
      "Epoch 48/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0192 - accuracy: 0.9973\n",
      "Epoch 49/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0192 - accuracy: 0.9974\n",
      "Epoch 50/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0193 - accuracy: 0.9974\n",
      "Epoch 51/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0193 - accuracy: 0.9975\n",
      "Epoch 52/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0194 - accuracy: 0.9975\n",
      "Epoch 53/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0195 - accuracy: 0.9974\n",
      "Epoch 54/256\n",
      "10807/10807 [==============================] - 11s 1ms/step - loss: 0.0196 - accuracy: 0.9975\n",
      "Epoch 55/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0196 - accuracy: 0.9975\n",
      "Epoch 56/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0197 - accuracy: 0.9976\n",
      "Epoch 57/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0198 - accuracy: 0.9976\n",
      "Epoch 58/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0198 - accuracy: 0.9976\n",
      "Epoch 59/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0198 - accuracy: 0.9976\n",
      "Epoch 60/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0199 - accuracy: 0.9976\n",
      "Epoch 61/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0200 - accuracy: 0.9976\n",
      "Epoch 62/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0201 - accuracy: 0.9976\n",
      "Epoch 63/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0202 - accuracy: 0.9977\n",
      "Epoch 64/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0202 - accuracy: 0.9977\n",
      "Epoch 65/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0204 - accuracy: 0.9977\n",
      "Epoch 66/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0204 - accuracy: 0.9977\n",
      "Epoch 67/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0206 - accuracy: 0.9977\n",
      "Epoch 68/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0206 - accuracy: 0.9977\n",
      "Epoch 69/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0207 - accuracy: 0.9977\n",
      "Epoch 70/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0208 - accuracy: 0.9977\n",
      "Epoch 71/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0209 - accuracy: 0.9977\n",
      "Epoch 72/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0209 - accuracy: 0.9978\n",
      "Epoch 73/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0210 - accuracy: 0.9978\n",
      "Epoch 74/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0211 - accuracy: 0.9978\n",
      "Epoch 75/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0212 - accuracy: 0.9978\n",
      "Epoch 76/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0212 - accuracy: 0.9978\n",
      "Epoch 77/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0213 - accuracy: 0.9978\n",
      "Epoch 78/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0214 - accuracy: 0.9978\n",
      "Epoch 79/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0215 - accuracy: 0.9978\n",
      "Epoch 80/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0216 - accuracy: 0.9978\n",
      "Epoch 81/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0217 - accuracy: 0.9978\n",
      "Epoch 82/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0218 - accuracy: 0.9978\n",
      "Epoch 83/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0219 - accuracy: 0.9978\n",
      "Epoch 84/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0219 - accuracy: 0.9978\n",
      "Epoch 85/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0219 - accuracy: 0.9978\n",
      "Epoch 86/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0220 - accuracy: 0.9978\n",
      "Epoch 87/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0221 - accuracy: 0.9978\n",
      "Epoch 88/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0222 - accuracy: 0.9978\n",
      "Epoch 89/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0222 - accuracy: 0.9978\n",
      "Epoch 90/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0223 - accuracy: 0.9978\n",
      "Epoch 91/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0223 - accuracy: 0.9978\n",
      "Epoch 92/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0224 - accuracy: 0.9978\n",
      "Epoch 93/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0225 - accuracy: 0.9978\n",
      "Epoch 94/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0226 - accuracy: 0.9978\n",
      "Epoch 95/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0227 - accuracy: 0.9978\n",
      "Epoch 96/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0227 - accuracy: 0.9978\n",
      "Epoch 97/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0228 - accuracy: 0.9979\n",
      "Epoch 98/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0229 - accuracy: 0.9978\n",
      "Epoch 99/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0230 - accuracy: 0.9978\n",
      "Epoch 100/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0231 - accuracy: 0.9978\n",
      "Epoch 101/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0232 - accuracy: 0.9978\n",
      "Epoch 102/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0232 - accuracy: 0.9978\n",
      "Epoch 103/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0233 - accuracy: 0.9979\n",
      "Epoch 104/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0234 - accuracy: 0.9979\n",
      "Epoch 105/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0235 - accuracy: 0.9978\n",
      "Epoch 106/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0235 - accuracy: 0.9979\n",
      "Epoch 107/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0236 - accuracy: 0.9979\n",
      "Epoch 108/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0236 - accuracy: 0.9979\n",
      "Epoch 109/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0237 - accuracy: 0.9979\n",
      "Epoch 110/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0237 - accuracy: 0.9979\n",
      "Epoch 111/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0238 - accuracy: 0.9979\n",
      "Epoch 112/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0239 - accuracy: 0.9979\n",
      "Epoch 113/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0240 - accuracy: 0.9979\n",
      "Epoch 114/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0240 - accuracy: 0.9979\n",
      "Epoch 115/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0241 - accuracy: 0.9979\n",
      "Epoch 116/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0242 - accuracy: 0.9979\n",
      "Epoch 117/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0243 - accuracy: 0.9979\n",
      "Epoch 118/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0243 - accuracy: 0.9980\n",
      "Epoch 119/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0243 - accuracy: 0.9979\n",
      "Epoch 120/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0245 - accuracy: 0.9980\n",
      "Epoch 121/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0245 - accuracy: 0.9979\n",
      "Epoch 122/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0245 - accuracy: 0.9980\n",
      "Epoch 123/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0246 - accuracy: 0.9980\n",
      "Epoch 124/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0247 - accuracy: 0.9979\n",
      "Epoch 125/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0248 - accuracy: 0.9980\n",
      "Epoch 126/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0248 - accuracy: 0.9980\n",
      "Epoch 127/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0249 - accuracy: 0.9980\n",
      "Epoch 128/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0249 - accuracy: 0.9980\n",
      "Epoch 129/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0250 - accuracy: 0.9980\n",
      "Epoch 130/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0251 - accuracy: 0.9980\n",
      "Epoch 131/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0251 - accuracy: 0.9980\n",
      "Epoch 132/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0251 - accuracy: 0.9980\n",
      "Epoch 133/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0252 - accuracy: 0.9980\n",
      "Epoch 134/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0252 - accuracy: 0.9980\n",
      "Epoch 135/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0253 - accuracy: 0.9980\n",
      "Epoch 136/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0254 - accuracy: 0.9980\n",
      "Epoch 137/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0254 - accuracy: 0.9980\n",
      "Epoch 138/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0255 - accuracy: 0.9980\n",
      "Epoch 139/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0255 - accuracy: 0.9980\n",
      "Epoch 140/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0256 - accuracy: 0.9980\n",
      "Epoch 141/256\n",
      "10807/10807 [==============================] - 11s 1ms/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 142/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 143/256\n",
      "10807/10807 [==============================] - 11s 999us/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 144/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0258 - accuracy: 0.9980\n",
      "Epoch 145/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0258 - accuracy: 0.9980\n",
      "Epoch 146/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0259 - accuracy: 0.9980\n",
      "Epoch 147/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0260 - accuracy: 0.9980\n",
      "Epoch 148/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0260 - accuracy: 0.9980\n",
      "Epoch 149/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0261 - accuracy: 0.9980\n",
      "Epoch 150/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0261 - accuracy: 0.9980\n",
      "Epoch 151/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 152/256\n",
      "10807/10807 [==============================] - 12s 1ms/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 153/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0263 - accuracy: 0.9980\n",
      "Epoch 154/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0264 - accuracy: 0.9980\n",
      "Epoch 155/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0264 - accuracy: 0.9980\n",
      "Epoch 156/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0265 - accuracy: 0.9980\n",
      "Epoch 157/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0265 - accuracy: 0.9980\n",
      "Epoch 158/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0266 - accuracy: 0.9980\n",
      "Epoch 159/256\n",
      "10807/10807 [==============================] - ETA: 0s - loss: 0.0267 - accuracy: 0.99 - 14s 1ms/step - loss: 0.0267 - accuracy: 0.9980\n",
      "Epoch 160/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0268 - accuracy: 0.9980\n",
      "Epoch 161/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0268 - accuracy: 0.9980\n",
      "Epoch 162/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0268 - accuracy: 0.9980\n",
      "Epoch 163/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0269 - accuracy: 0.9980\n",
      "Epoch 164/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0270 - accuracy: 0.9980\n",
      "Epoch 165/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0270 - accuracy: 0.9980\n",
      "Epoch 166/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0271 - accuracy: 0.9980\n",
      "Epoch 167/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0272 - accuracy: 0.9980\n",
      "Epoch 168/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0272 - accuracy: 0.9980\n",
      "Epoch 169/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0273 - accuracy: 0.9980\n",
      "Epoch 170/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0273 - accuracy: 0.9980\n",
      "Epoch 171/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0274 - accuracy: 0.9980\n",
      "Epoch 172/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0275 - accuracy: 0.9980\n",
      "Epoch 173/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0275 - accuracy: 0.9980\n",
      "Epoch 174/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0275 - accuracy: 0.9980\n",
      "Epoch 175/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0276 - accuracy: 0.9980\n",
      "Epoch 176/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0277 - accuracy: 0.9980\n",
      "Epoch 177/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0277 - accuracy: 0.9980\n",
      "Epoch 178/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0278 - accuracy: 0.9980\n",
      "Epoch 179/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0278 - accuracy: 0.9980\n",
      "Epoch 180/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 181/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 182/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0280 - accuracy: 0.9980\n",
      "Epoch 183/256\n",
      "10807/10807 [==============================] - 14s 1ms/step - loss: 0.0281 - accuracy: 0.9980\n",
      "Epoch 184/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0281 - accuracy: 0.9981\n",
      "Epoch 185/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0282 - accuracy: 0.9981\n",
      "Epoch 186/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0283 - accuracy: 0.9980\n",
      "Epoch 187/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0284 - accuracy: 0.9980\n",
      "Epoch 188/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0284 - accuracy: 0.9980\n",
      "Epoch 189/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0285 - accuracy: 0.9980\n",
      "Epoch 190/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0285 - accuracy: 0.9980\n",
      "Epoch 191/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0286 - accuracy: 0.9980\n",
      "Epoch 192/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0287 - accuracy: 0.9980\n",
      "Epoch 193/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0287 - accuracy: 0.9980\n",
      "Epoch 194/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0287 - accuracy: 0.9980\n",
      "Epoch 195/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0288 - accuracy: 0.9980\n",
      "Epoch 196/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0289 - accuracy: 0.9980\n",
      "Epoch 197/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0290 - accuracy: 0.9980\n",
      "Epoch 198/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0290 - accuracy: 0.9980\n",
      "Epoch 199/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0291 - accuracy: 0.9980\n",
      "Epoch 200/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0291 - accuracy: 0.9980\n",
      "Epoch 201/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0292 - accuracy: 0.9980\n",
      "Epoch 202/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0293 - accuracy: 0.9980\n",
      "Epoch 203/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0293 - accuracy: 0.9980\n",
      "Epoch 204/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0294 - accuracy: 0.9980\n",
      "Epoch 205/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0294 - accuracy: 0.9980\n",
      "Epoch 206/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0296 - accuracy: 0.9980\n",
      "Epoch 207/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0296 - accuracy: 0.9980\n",
      "Epoch 208/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0297 - accuracy: 0.9980\n",
      "Epoch 209/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0297 - accuracy: 0.9980\n",
      "Epoch 210/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0298 - accuracy: 0.9980\n",
      "Epoch 211/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0298 - accuracy: 0.9980\n",
      "Epoch 212/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0299 - accuracy: 0.9980\n",
      "Epoch 213/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0300 - accuracy: 0.9980\n",
      "Epoch 214/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0300 - accuracy: 0.9980\n",
      "Epoch 215/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0301 - accuracy: 0.9980\n",
      "Epoch 216/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0302 - accuracy: 0.9980\n",
      "Epoch 217/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0302 - accuracy: 0.9980\n",
      "Epoch 218/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0303 - accuracy: 0.9980\n",
      "Epoch 219/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0303 - accuracy: 0.9980\n",
      "Epoch 220/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0304 - accuracy: 0.9980\n",
      "Epoch 221/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0304 - accuracy: 0.9980\n",
      "Epoch 222/256\n",
      "10807/10807 [==============================] - 13s 1ms/step - loss: 0.0305 - accuracy: 0.9980\n",
      "Epoch 223/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0306 - accuracy: 0.9980\n",
      "Epoch 224/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0306 - accuracy: 0.9980\n",
      "Epoch 225/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0307 - accuracy: 0.9980\n",
      "Epoch 226/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0307 - accuracy: 0.9980\n",
      "Epoch 227/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0308 - accuracy: 0.9980\n",
      "Epoch 228/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0309 - accuracy: 0.9980\n",
      "Epoch 229/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0309 - accuracy: 0.9980\n",
      "Epoch 230/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0310 - accuracy: 0.9980\n",
      "Epoch 231/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0311 - accuracy: 0.9980\n",
      "Epoch 232/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0311 - accuracy: 0.9980\n",
      "Epoch 233/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0312 - accuracy: 0.9980\n",
      "Epoch 234/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0312 - accuracy: 0.9980\n",
      "Epoch 235/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0313 - accuracy: 0.9980\n",
      "Epoch 236/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0314 - accuracy: 0.9980\n",
      "Epoch 237/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0314 - accuracy: 0.9980\n",
      "Epoch 238/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0315 - accuracy: 0.9980\n",
      "Epoch 239/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0316 - accuracy: 0.9980\n",
      "Epoch 240/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0316 - accuracy: 0.9980\n",
      "Epoch 241/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0317 - accuracy: 0.9980\n",
      "Epoch 242/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0318 - accuracy: 0.9980\n",
      "Epoch 243/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0318 - accuracy: 0.9980\n",
      "Epoch 244/256\n",
      "10807/10807 [==============================] - 15s 1ms/step - loss: 0.0319 - accuracy: 0.9980\n",
      "Epoch 245/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0320 - accuracy: 0.9980\n",
      "Epoch 246/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0320 - accuracy: 0.9980\n",
      "Epoch 247/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0321 - accuracy: 0.9980\n",
      "Epoch 248/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0322 - accuracy: 0.9980\n",
      "Epoch 249/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0322 - accuracy: 0.9980\n",
      "Epoch 250/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0322 - accuracy: 0.9980\n",
      "Epoch 251/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0323 - accuracy: 0.9980\n",
      "Epoch 252/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0324 - accuracy: 0.9980\n",
      "Epoch 253/256\n",
      "10807/10807 [==============================] - 16s 2ms/step - loss: 0.0324 - accuracy: 0.9980\n",
      "Epoch 254/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0325 - accuracy: 0.9980\n",
      "Epoch 255/256\n",
      "10807/10807 [==============================] - 16s 1ms/step - loss: 0.0326 - accuracy: 0.9980\n",
      "Epoch 256/256\n",
      "10807/10807 [==============================] - 17s 2ms/step - loss: 0.0326 - accuracy: 0.9980\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24d9cb28100>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
    "model.fit(x_train_numpy, y_train_numpy, epochs = 256, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0df49377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 1)                 120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c5f077",
   "metadata": {},
   "source": [
    "### Model : 2. With more layers and neurons so that dataset can overfit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a4a90869",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(8, input_dim = len(X_numpy[0, :]), activation='relu'))\n",
    "model_2.add(Dense(4, activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daea94d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "10807/10807 [==============================] - 6s 483us/step - loss: 0.0882 - accuracy: 0.9919\n",
      "Epoch 2/32\n",
      "10807/10807 [==============================] - 5s 479us/step - loss: 0.0197 - accuracy: 0.9968\n",
      "Epoch 3/32\n",
      "10807/10807 [==============================] - 5s 481us/step - loss: 0.0184 - accuracy: 0.9973\n",
      "Epoch 4/32\n",
      "10807/10807 [==============================] - 5s 486us/step - loss: 0.0184 - accuracy: 0.9975\n",
      "Epoch 5/32\n",
      "10807/10807 [==============================] - 5s 482us/step - loss: 0.0183 - accuracy: 0.9975\n",
      "Epoch 6/32\n",
      "10807/10807 [==============================] - 5s 495us/step - loss: 0.0181 - accuracy: 0.9976\n",
      "Epoch 7/32\n",
      "10807/10807 [==============================] - 5s 486us/step - loss: 0.0180 - accuracy: 0.9976\n",
      "Epoch 8/32\n",
      "10807/10807 [==============================] - 5s 480us/step - loss: 0.0179 - accuracy: 0.9976\n",
      "Epoch 9/32\n",
      "10807/10807 [==============================] - 5s 493us/step - loss: 0.0178 - accuracy: 0.9977\n",
      "Epoch 10/32\n",
      "10807/10807 [==============================] - 5s 507us/step - loss: 0.0176 - accuracy: 0.9977\n",
      "Epoch 11/32\n",
      "10807/10807 [==============================] - 5s 500us/step - loss: 0.0176 - accuracy: 0.9977\n",
      "Epoch 12/32\n",
      "10807/10807 [==============================] - 5s 489us/step - loss: 0.0178 - accuracy: 0.9977\n",
      "Epoch 13/32\n",
      "10807/10807 [==============================] - 5s 491us/step - loss: 0.0178 - accuracy: 0.9977\n",
      "Epoch 14/32\n",
      "10807/10807 [==============================] - 5s 483us/step - loss: 0.0178 - accuracy: 0.9978\n",
      "Epoch 15/32\n",
      "10807/10807 [==============================] - 5s 487us/step - loss: 0.0180 - accuracy: 0.9977\n",
      "Epoch 16/32\n",
      "10807/10807 [==============================] - 5s 493us/step - loss: 0.0178 - accuracy: 0.9977\n",
      "Epoch 17/32\n",
      "10807/10807 [==============================] - 6s 516us/step - loss: 0.0178 - accuracy: 0.9977\n",
      "Epoch 18/32\n",
      "10807/10807 [==============================] - 5s 508us/step - loss: 0.0181 - accuracy: 0.9977\n",
      "Epoch 19/32\n",
      "10807/10807 [==============================] - 6s 528us/step - loss: 0.0181 - accuracy: 0.9977\n",
      "Epoch 20/32\n",
      "  494/10807 [>.............................] - ETA: 6s - loss: 0.0192 - accuracy: 0.9977"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
    "model_2.fit(x_train_numpy, y_train_numpy, epochs = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f5f2324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Validation Data:\n",
      "[0 0 0 1 0 1 1 0 0 0]\n",
      "Prediction:\n",
      "[[7.0481242e-06 2.2987747e-08 6.7529127e-06 9.7435486e-01 6.7563465e-06\n",
      "  9.8804760e-01 9.9964744e-01 6.7529127e-06 6.7529127e-06 6.8989330e-06]]\n"
     ]
    }
   ],
   "source": [
    "print ('True Validation Data:')\n",
    "print(y_train_numpy[:10])\n",
    "prediction = model.predict(x_train_numpy)\n",
    "print ('Prediction:')\n",
    "print(prediction[0:10].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d754acd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c79a90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
