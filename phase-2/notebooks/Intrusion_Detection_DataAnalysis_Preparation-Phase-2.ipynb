{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c70fae2",
   "metadata": {},
   "source": [
    "## Phase - 2: Predicting Anomalies in Network Traffic (A Binary Classification problem)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7850a823",
   "metadata": {},
   "source": [
    "### Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef65168",
   "metadata": {},
   "source": [
    "- The main goal in this phase is to experiment and find what network size is needed to 'overfit' the entire dataset at your hand.\n",
    "- In other words, we want to determine how big architecture we need to overfit the data. \n",
    "- The place to start is to use 'logistic regression' model and train for as many epochs as needed to obtain as high accuracy as possible. After training hundreds of epochs if you observe that the accuracy is not increasing then it implies that the number of neurons in your model (only one) may not be sufficient for overfitting. \n",
    "- The next step is to grow your model into a multi-layer model and add a few neurons (say only 2) in the input layer. This way your model will have '2 + 1 = 3' neurons in total. \n",
    "- If your accuracy still does not each a 100% or close to 100% you can continue to increase the number of layers and number of neurons. Once you have obtained 100% accuracy (or around 100%) your experiments for this phase are complete. - The results of this experiment also inform us that our final model (in subsequent phases) should be smaller than this model. Small here refers to number of layers and number of neurons in each layer.\n",
    "\n",
    "[BONUS] You will be eligible to receive up to 2 bonus points if you complete this phase without using the Keras/Tenforflow library, i.e., if you implement your own Python code to build neural network (or logistic regression model) and code a function that serves as an optimizer (for example, gradient descent algorithm) to train your model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a55b77",
   "metadata": {},
   "source": [
    "### Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe26c13",
   "metadata": {},
   "source": [
    "- This phase-2 of the \"Predicting Anamolies in Network Traffic\" is a continuation to the phase-1 of the project which can be found here - https://github.com/reshma2303/AI5300/tree/main/phase-1-data-analysis\n",
    "- In this phase - 2, below things will be accomplished as requested in the above problem statement:\n",
    "    - Step-1: Using ENTIRE dataset to \"OVERFIT\" the model using vannila (single neuron) logistic regression model to reach accuracy 100% or close to 10%\n",
    "    - Step-2: If the accuracy did not reach 100%, then a bigger architecture model will be designed and modeled to achieve accuracy of 100% or close to 100%.\n",
    "        \n",
    "\n",
    "        \n",
    "  NOTE: \n",
    "  \n",
    "    - The detailed analysis of the dataset is covered in the phase-1 of the project.\n",
    "    - As requested in the problem statement, entire dataset will be used to overfit the model and no shuffling or train-test split will happen as these steps are covered in subsequent phases of the project\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8c632f",
   "metadata": {},
   "source": [
    "### 1. Data Load and Pre-Processing required for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adce1f2c",
   "metadata": {},
   "source": [
    "#### Categorical Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eec0a85",
   "metadata": {},
   "source": [
    "'protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f323bffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "catg_cols = ['protocol_type', 'service', 'flag', 'land', 'logged_in', 'is_host_login', 'is_guest_login']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d856cbab",
   "metadata": {},
   "source": [
    "#### Continuous Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb50db86",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols = [ 'duration', 'src_bytes', 'dst_bytes', 'wrong_fragment', 'urgent', 'hot', 'num_failed_logins', 'num_compromised', 'root_shell', 'su_attempted', 'num_root', 'num_file_creations', 'num_shells', 'num_access_files', 'num_outbound_cmds', 'count', 'srv_count', 'serror_rate', 'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate', 'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count', 'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate', 'dst_host_srv_diff_host_rate', 'dst_host_serror_rate', 'dst_host_srv_serror_rate', 'dst_host_rerror_rate', 'dst_host_srv_rerror_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7abccd61",
   "metadata": {},
   "source": [
    "#### Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b434d3",
   "metadata": {},
   "source": [
    "The target variable \"label\" contains all different types of malware attacks and also the value \"normal\" (i.e., not an attack) as shown below.\n",
    "\n",
    "'normal', 'buffer_overflow', 'loadmodule', 'perl', 'neptune', 'smurf', 'guess_passwd', 'pod', 'teardrop', 'portsweep', 'ipsweep', 'land', 'ftp_write', 'back', 'imap', 'satan', 'phf', 'nmap', 'multihop', 'warezmaster', 'warezclient', 'spy', 'rootkit'\n",
    "\n",
    "All malware attacks are grouped (transformed) to the value \"abnormal\" to make this problem a binary classification problem instead of a multi-class classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3986fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'label'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ccae6cd",
   "metadata": {},
   "source": [
    "#### Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36e844e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"../datasets/kddcup99_csv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c8f74",
   "metadata": {},
   "source": [
    "#### Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3059174e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac162b93",
   "metadata": {},
   "source": [
    "494020 records with 41 features and 1 target variable (\"label\") for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95f9b3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>49</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp    http   SF        181       5450     0   \n",
       "1         0           tcp    http   SF        239        486     0   \n",
       "2         0           tcp    http   SF        235       1337     0   \n",
       "3         0           tcp    http   SF        219       1337     0   \n",
       "4         0           tcp    http   SF        217       2032     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
       "0               0       0    0  ...                   9   \n",
       "1               0       0    0  ...                  19   \n",
       "2               0       0    0  ...                  29   \n",
       "3               0       0    0  ...                  39   \n",
       "4               0       0    0  ...                  49   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                     1.0                     0.0   \n",
       "1                     1.0                     0.0   \n",
       "2                     1.0                     0.0   \n",
       "3                     1.0                     0.0   \n",
       "4                     1.0                     0.0   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.11                          0.0   \n",
       "1                         0.05                          0.0   \n",
       "2                         0.03                          0.0   \n",
       "3                         0.03                          0.0   \n",
       "4                         0.02                          0.0   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                   0.0                       0.0                   0.0   \n",
       "1                   0.0                       0.0                   0.0   \n",
       "2                   0.0                       0.0                   0.0   \n",
       "3                   0.0                       0.0                   0.0   \n",
       "4                   0.0                       0.0                   0.0   \n",
       "\n",
       "   dst_host_srv_rerror_rate   label  \n",
       "0                       0.0  normal  \n",
       "1                       0.0  normal  \n",
       "2                       0.0  normal  \n",
       "3                       0.0  normal  \n",
       "4                       0.0  normal  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a6d066",
   "metadata": {},
   "source": [
    "As seen above, there are various type of malware attacks which can be grouped as \"abnormal\" to make this problem as binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32104edd",
   "metadata": {},
   "source": [
    "##### Group all malware attacks as \"abnormal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c866ed99",
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_types = list(df['label'].unique())\n",
    "attack_types.remove('normal') # remove normal from attack types as we only want malware attacks to convert as abnormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90dc8e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 42)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].replace(attack_types, 'abnormal')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e77267f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abnormal    396743\n",
       "normal       97277\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39174e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol_type     object\n",
       "service           object\n",
       "flag              object\n",
       "land               int64\n",
       "logged_in          int64\n",
       "is_host_login      int64\n",
       "is_guest_login     int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[catg_cols].dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe945967",
   "metadata": {},
   "source": [
    "As seen from the above datatypes of the categorical columns,the column values are not strings. We need to convert them to string before performing any analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32474eda",
   "metadata": {},
   "source": [
    "##### Fixing the data types of categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad980c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "protocol_type     object\n",
       "service           object\n",
       "flag              object\n",
       "land              object\n",
       "logged_in         object\n",
       "is_host_login     object\n",
       "is_guest_login    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['protocol_type'] = df['protocol_type'].astype(str)\n",
    "df['service'] = df['service'].astype(str)\n",
    "df['flag'] = df['flag'].astype(str)\n",
    "df['land'] = df['land'].astype(str)\n",
    "df['logged_in'] = df['logged_in'].astype(str)\n",
    "df['is_host_login'] = df['is_host_login'].astype(str)\n",
    "df['is_guest_login'] = df['is_guest_login'].astype(str)\n",
    "df[catg_cols].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6fdfb144",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['is_host_login'], inplace=True)\n",
    "df.drop(columns=['num_outbound_cmds'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc893c2",
   "metadata": {},
   "source": [
    "### Transform Target Binary label to 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "395e1caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    396743\n",
       "1     97277\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['label'].map({'normal': 1, 'abnormal': 0})\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e246b98",
   "metadata": {},
   "source": [
    "### One hot encode categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be8e7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_categorical_to_one_hot_encoding(dataset, column_name):\n",
    "    dummy_values = pd.get_dummies(dataset[column_name])\n",
    "    \n",
    "    for category in dummy_values.columns:\n",
    "        dummy_value_name = f\"{column_name}-{category}\"\n",
    "        dataset[dummy_value_name] = dummy_values[category]\n",
    "    dataset.drop(column_name, axis=1, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1854b7d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 120)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for cat_col in catg_cols:\n",
    "    if cat_col != \"is_host_login\":\n",
    "        convert_categorical_to_one_hot_encoding(df, cat_col)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d0ebdcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>flag-S2</th>\n",
       "      <th>flag-S3</th>\n",
       "      <th>flag-SF</th>\n",
       "      <th>flag-SH</th>\n",
       "      <th>land-0</th>\n",
       "      <th>land-1</th>\n",
       "      <th>logged_in-0</th>\n",
       "      <th>logged_in-1</th>\n",
       "      <th>is_guest_login-0</th>\n",
       "      <th>is_guest_login-1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>5450</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>239</td>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>235</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>219</td>\n",
       "      <td>1337</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>217</td>\n",
       "      <td>2032</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  src_bytes  dst_bytes  wrong_fragment  urgent  hot  \\\n",
       "0         0        181       5450               0       0    0   \n",
       "1         0        239        486               0       0    0   \n",
       "2         0        235       1337               0       0    0   \n",
       "3         0        219       1337               0       0    0   \n",
       "4         0        217       2032               0       0    0   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  ...  flag-S2  \\\n",
       "0                  0                0           0             0  ...        0   \n",
       "1                  0                0           0             0  ...        0   \n",
       "2                  0                0           0             0  ...        0   \n",
       "3                  0                0           0             0  ...        0   \n",
       "4                  0                0           0             0  ...        0   \n",
       "\n",
       "   flag-S3  flag-SF  flag-SH  land-0  land-1  logged_in-0  logged_in-1  \\\n",
       "0        0        1        0       1       0            0            1   \n",
       "1        0        1        0       1       0            0            1   \n",
       "2        0        1        0       1       0            0            1   \n",
       "3        0        1        0       1       0            0            1   \n",
       "4        0        1        0       1       0            0            1   \n",
       "\n",
       "   is_guest_login-0  is_guest_login-1  \n",
       "0                 1                 0  \n",
       "1                 1                 0  \n",
       "2                 1                 0  \n",
       "3                 1                 0  \n",
       "4                 1                 0  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2ded3a",
   "metadata": {},
   "source": [
    "###### Shuffle DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a7b2faf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6d59f3",
   "metadata": {},
   "source": [
    "### Data Normalization (scaling numerical features to unit norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c05167",
   "metadata": {},
   "source": [
    "As seen from the above continous variables distribution in the section 2.6 the scale of some of the features (columns) values are not in same range as others.\n",
    "Hence the features need to be normalized so that the optimization during model training will happen in a better way and the model will not be sensitive to the features."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f502ede",
   "metadata": {},
   "source": [
    "# Using Min-max normalization\n",
    "min = X.min(axis = 0) \n",
    "max = X.max(axis = 0) \n",
    "X = (X - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb943aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_cols_new = [each for each in cont_cols if each!='num_outbound_cmds']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42e2b291",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_CONTCOLS_MIN = df[cont_cols_new].min(axis=0)\n",
    "df_CONTCOLS_MAX = df[cont_cols_new].max(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5317830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[cont_cols_new] = (df[cont_cols_new] - df_CONTCOLS_MIN) / (df_CONTCOLS_MAX - df_CONTCOLS_MIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c369d77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>root_shell</th>\n",
       "      <th>su_attempted</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.047769e-08</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584314</td>\n",
       "      <td>0.447059</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.003922</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.488371e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.488371e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.369926e-07</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619608</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration     src_bytes  dst_bytes  wrong_fragment  urgent  hot  \\\n",
       "0       0.0  5.047769e-08   0.000018             0.0     0.0  0.0   \n",
       "1       0.0  0.000000e+00   0.000000             0.0     0.0  0.0   \n",
       "2       0.0  1.488371e-06   0.000000             0.0     0.0  0.0   \n",
       "3       0.0  1.488371e-06   0.000000             0.0     0.0  0.0   \n",
       "4       0.0  4.369926e-07   0.000389             0.0     0.0  0.0   \n",
       "\n",
       "   num_failed_logins  num_compromised  root_shell  su_attempted  ...  \\\n",
       "0                0.0              0.0         0.0           0.0  ...   \n",
       "1                0.0              0.0         0.0           0.0  ...   \n",
       "2                0.0              0.0         0.0           0.0  ...   \n",
       "3                0.0              0.0         0.0           0.0  ...   \n",
       "4                0.0              0.0         0.0           0.0  ...   \n",
       "\n",
       "   dst_host_count  dst_host_srv_count  dst_host_same_srv_rate  \\\n",
       "0        0.584314            0.447059                    0.77   \n",
       "1        1.000000            0.003922                    0.00   \n",
       "2        1.000000            1.000000                    1.00   \n",
       "3        1.000000            1.000000                    1.00   \n",
       "4        0.619608            1.000000                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.01   \n",
       "1                    1.00                         1.00   \n",
       "2                    0.00                         1.00   \n",
       "3                    0.00                         1.00   \n",
       "4                    0.00                         0.01   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                   0.0   \n",
       "1                         0.00                   0.0   \n",
       "2                         0.00                   0.0   \n",
       "3                         0.00                   0.0   \n",
       "4                         0.05                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \n",
       "0                       0.0                   0.0                       0.0  \n",
       "1                       0.0                   1.0                       1.0  \n",
       "2                       0.0                   0.0                       0.0  \n",
       "3                       0.0                   0.0                       0.0  \n",
       "4                       0.0                   0.0                       0.0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[cont_cols_new].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf675cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().values.any() # making sure there are no NaN values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d11017e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_numpy = df.drop(columns=['label']).to_numpy()\n",
    "Y_numpy = df['label'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e41145e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020, 119)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numpy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3e9e7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(494020,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_numpy.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030e5720",
   "metadata": {},
   "source": [
    "### 2. Model Building (Phase-2: Model that overfits entire dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ee3a5e",
   "metadata": {},
   "source": [
    "#### Step-1: With single neuron logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e731349b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6428c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(1, input_dim = len(X_numpy[0, :]), activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e967cb75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0440 - accuracy: 0.9857\n",
      "Epoch 2/256\n",
      "15439/15439 [==============================] - 7s 452us/step - loss: 0.0265 - accuracy: 0.9915\n",
      "Epoch 3/256\n",
      "15439/15439 [==============================] - 7s 456us/step - loss: 0.0242 - accuracy: 0.9915\n",
      "Epoch 4/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0231 - accuracy: 0.9915\n",
      "Epoch 5/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0223 - accuracy: 0.9916\n",
      "Epoch 6/256\n",
      "15439/15439 [==============================] - 7s 449us/step - loss: 0.0218 - accuracy: 0.9916\n",
      "Epoch 7/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0215 - accuracy: 0.9918\n",
      "Epoch 8/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0211 - accuracy: 0.9920\n",
      "Epoch 9/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0208 - accuracy: 0.9923\n",
      "Epoch 10/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0207 - accuracy: 0.9925\n",
      "Epoch 11/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0203 - accuracy: 0.9928\n",
      "Epoch 12/256\n",
      "15439/15439 [==============================] - 7s 473us/step - loss: 0.0202 - accuracy: 0.9929\n",
      "Epoch 13/256\n",
      "15439/15439 [==============================] - 8s 489us/step - loss: 0.0201 - accuracy: 0.9931\n",
      "Epoch 14/256\n",
      "15439/15439 [==============================] - 7s 464us/step - loss: 0.0198 - accuracy: 0.9932\n",
      "Epoch 15/256\n",
      "15439/15439 [==============================] - 7s 442us/step - loss: 0.0197 - accuracy: 0.9932\n",
      "Epoch 16/256\n",
      "15439/15439 [==============================] - 7s 452us/step - loss: 0.0198 - accuracy: 0.9933\n",
      "Epoch 17/256\n",
      "15439/15439 [==============================] - 7s 479us/step - loss: 0.0195 - accuracy: 0.9933\n",
      "Epoch 18/256\n",
      "15439/15439 [==============================] - 7s 470us/step - loss: 0.0195 - accuracy: 0.9934\n",
      "Epoch 19/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0196 - accuracy: 0.9934\n",
      "Epoch 20/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0195 - accuracy: 0.9940\n",
      "Epoch 21/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0193 - accuracy: 0.9944\n",
      "Epoch 22/256\n",
      "15439/15439 [==============================] - 7s 456us/step - loss: 0.0194 - accuracy: 0.9949\n",
      "Epoch 23/256\n",
      "15439/15439 [==============================] - 7s 463us/step - loss: 0.0194 - accuracy: 0.9956\n",
      "Epoch 24/256\n",
      "15439/15439 [==============================] - 7s 474us/step - loss: 0.0194 - accuracy: 0.9959\n",
      "Epoch 25/256\n",
      "15439/15439 [==============================] - 7s 453us/step - loss: 0.0195 - accuracy: 0.9963\n",
      "Epoch 26/256\n",
      "15439/15439 [==============================] - 7s 452us/step - loss: 0.0194 - accuracy: 0.9966\n",
      "Epoch 27/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0194 - accuracy: 0.9967\n",
      "Epoch 28/256\n",
      "15439/15439 [==============================] - 7s 442us/step - loss: 0.0195 - accuracy: 0.9968\n",
      "Epoch 29/256\n",
      "15439/15439 [==============================] - 7s 463us/step - loss: 0.0195 - accuracy: 0.9969\n",
      "Epoch 30/256\n",
      "15439/15439 [==============================] - 7s 470us/step - loss: 0.0196 - accuracy: 0.9969\n",
      "Epoch 31/256\n",
      "15439/15439 [==============================] - 8s 488us/step - loss: 0.0197 - accuracy: 0.9971\n",
      "Epoch 32/256\n",
      "15439/15439 [==============================] - 7s 478us/step - loss: 0.0197 - accuracy: 0.9972\n",
      "Epoch 33/256\n",
      "15439/15439 [==============================] - 8s 500us/step - loss: 0.0197 - accuracy: 0.9973\n",
      "Epoch 34/256\n",
      "15439/15439 [==============================] - 8s 529us/step - loss: 0.0197 - accuracy: 0.9973\n",
      "Epoch 35/256\n",
      "15439/15439 [==============================] - 7s 458us/step - loss: 0.0198 - accuracy: 0.9973\n",
      "Epoch 36/256\n",
      "15439/15439 [==============================] - 7s 484us/step - loss: 0.0197 - accuracy: 0.9974\n",
      "Epoch 37/256\n",
      "15439/15439 [==============================] - 8s 511us/step - loss: 0.0198 - accuracy: 0.9974\n",
      "Epoch 38/256\n",
      "15439/15439 [==============================] - 7s 473us/step - loss: 0.0199 - accuracy: 0.9975\n",
      "Epoch 39/256\n",
      "15439/15439 [==============================] - 7s 465us/step - loss: 0.0199 - accuracy: 0.9975\n",
      "Epoch 40/256\n",
      "15439/15439 [==============================] - 7s 470us/step - loss: 0.0200 - accuracy: 0.9975\n",
      "Epoch 41/256\n",
      "15439/15439 [==============================] - 7s 469us/step - loss: 0.0200 - accuracy: 0.9975\n",
      "Epoch 42/256\n",
      "15439/15439 [==============================] - 7s 475us/step - loss: 0.0200 - accuracy: 0.9975\n",
      "Epoch 43/256\n",
      "15439/15439 [==============================] - 8s 486us/step - loss: 0.0200 - accuracy: 0.9976\n",
      "Epoch 44/256\n",
      "15439/15439 [==============================] - 8s 516us/step - loss: 0.0201 - accuracy: 0.9976\n",
      "Epoch 45/256\n",
      "15439/15439 [==============================] - 7s 474us/step - loss: 0.0202 - accuracy: 0.9976\n",
      "Epoch 46/256\n",
      "15439/15439 [==============================] - 7s 476us/step - loss: 0.0202 - accuracy: 0.9976\n",
      "Epoch 47/256\n",
      "15439/15439 [==============================] - 7s 459us/step - loss: 0.0203 - accuracy: 0.9976\n",
      "Epoch 48/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0203 - accuracy: 0.9976\n",
      "Epoch 49/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0204 - accuracy: 0.9976\n",
      "Epoch 50/256\n",
      "15439/15439 [==============================] - 7s 451us/step - loss: 0.0205 - accuracy: 0.9976\n",
      "Epoch 51/256\n",
      "15439/15439 [==============================] - 8s 490us/step - loss: 0.0206 - accuracy: 0.9976\n",
      "Epoch 52/256\n",
      "15439/15439 [==============================] - 7s 477us/step - loss: 0.0206 - accuracy: 0.9977\n",
      "Epoch 53/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0206 - accuracy: 0.9977\n",
      "Epoch 54/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0206 - accuracy: 0.9977\n",
      "Epoch 55/256\n",
      "15439/15439 [==============================] - 7s 470us/step - loss: 0.0207 - accuracy: 0.9977\n",
      "Epoch 56/256\n",
      "15439/15439 [==============================] - 7s 459us/step - loss: 0.0208 - accuracy: 0.9977\n",
      "Epoch 57/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0208 - accuracy: 0.9978\n",
      "Epoch 58/256\n",
      "15439/15439 [==============================] - 7s 458us/step - loss: 0.0209 - accuracy: 0.9977\n",
      "Epoch 59/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0210 - accuracy: 0.9977\n",
      "Epoch 60/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0210 - accuracy: 0.9978\n",
      "Epoch 61/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0212 - accuracy: 0.9978\n",
      "Epoch 62/256\n",
      "15439/15439 [==============================] - 7s 463us/step - loss: 0.0212 - accuracy: 0.9978\n",
      "Epoch 63/256\n",
      "15439/15439 [==============================] - 7s 466us/step - loss: 0.0213 - accuracy: 0.9978\n",
      "Epoch 64/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0213 - accuracy: 0.9978\n",
      "Epoch 65/256\n",
      "15439/15439 [==============================] - 7s 456us/step - loss: 0.0215 - accuracy: 0.9978\n",
      "Epoch 66/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0215 - accuracy: 0.9978\n",
      "Epoch 67/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0217 - accuracy: 0.9978\n",
      "Epoch 68/256\n",
      "15439/15439 [==============================] - 7s 465us/step - loss: 0.0217 - accuracy: 0.9978\n",
      "Epoch 69/256\n",
      "15439/15439 [==============================] - 7s 435us/step - loss: 0.0218 - accuracy: 0.9978\n",
      "Epoch 70/256\n",
      "15439/15439 [==============================] - 7s 466us/step - loss: 0.0219 - accuracy: 0.9978\n",
      "Epoch 71/256\n",
      "15439/15439 [==============================] - 7s 471us/step - loss: 0.0220 - accuracy: 0.9978\n",
      "Epoch 72/256\n",
      "15439/15439 [==============================] - 7s 459us/step - loss: 0.0221 - accuracy: 0.9978\n",
      "Epoch 73/256\n",
      "15439/15439 [==============================] - 7s 466us/step - loss: 0.0221 - accuracy: 0.9978\n",
      "Epoch 74/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0222 - accuracy: 0.9978\n",
      "Epoch 75/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0223 - accuracy: 0.9978\n",
      "Epoch 76/256\n",
      "15439/15439 [==============================] - 7s 448us/step - loss: 0.0224 - accuracy: 0.9978\n",
      "Epoch 77/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0225 - accuracy: 0.9978\n",
      "Epoch 78/256\n",
      "15439/15439 [==============================] - 7s 468us/step - loss: 0.0226 - accuracy: 0.9978\n",
      "Epoch 79/256\n",
      "15439/15439 [==============================] - 7s 460us/step - loss: 0.0227 - accuracy: 0.9978\n",
      "Epoch 80/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0227 - accuracy: 0.9978\n",
      "Epoch 81/256\n",
      "15439/15439 [==============================] - 7s 456us/step - loss: 0.0228 - accuracy: 0.9978\n",
      "Epoch 82/256\n",
      "15439/15439 [==============================] - 7s 481us/step - loss: 0.0229 - accuracy: 0.9978\n",
      "Epoch 83/256\n",
      "15439/15439 [==============================] - 7s 483us/step - loss: 0.0229 - accuracy: 0.9978\n",
      "Epoch 84/256\n",
      "15439/15439 [==============================] - 8s 490us/step - loss: 0.0230 - accuracy: 0.9978\n",
      "Epoch 85/256\n",
      "15439/15439 [==============================] - 7s 482us/step - loss: 0.0231 - accuracy: 0.9978\n",
      "Epoch 86/256\n",
      "15439/15439 [==============================] - 7s 464us/step - loss: 0.0231 - accuracy: 0.9978\n",
      "Epoch 87/256\n",
      "15439/15439 [==============================] - 7s 464us/step - loss: 0.0232 - accuracy: 0.9979\n",
      "Epoch 88/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0233 - accuracy: 0.9979\n",
      "Epoch 89/256\n",
      "15439/15439 [==============================] - 7s 448us/step - loss: 0.0234 - accuracy: 0.9979\n",
      "Epoch 90/256\n",
      "15439/15439 [==============================] - 7s 458us/step - loss: 0.0234 - accuracy: 0.9979\n",
      "Epoch 91/256\n",
      "15439/15439 [==============================] - 7s 459us/step - loss: 0.0234 - accuracy: 0.9979\n",
      "Epoch 92/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0235 - accuracy: 0.9979\n",
      "Epoch 93/256\n",
      "15439/15439 [==============================] - 7s 469us/step - loss: 0.0236 - accuracy: 0.9979\n",
      "Epoch 94/256\n",
      "15439/15439 [==============================] - 8s 488us/step - loss: 0.0237 - accuracy: 0.9979\n",
      "Epoch 95/256\n",
      "15439/15439 [==============================] - 8s 488us/step - loss: 0.0237 - accuracy: 0.9979\n",
      "Epoch 96/256\n",
      "15439/15439 [==============================] - 8s 487us/step - loss: 0.0238 - accuracy: 0.9979\n",
      "Epoch 97/256\n",
      "15439/15439 [==============================] - 7s 478us/step - loss: 0.0239 - accuracy: 0.9979\n",
      "Epoch 98/256\n",
      "15439/15439 [==============================] - 7s 464us/step - loss: 0.0239 - accuracy: 0.9979\n",
      "Epoch 99/256\n",
      "15439/15439 [==============================] - 7s 472us/step - loss: 0.0240 - accuracy: 0.9979\n",
      "Epoch 100/256\n",
      "15439/15439 [==============================] - 7s 481us/step - loss: 0.0241 - accuracy: 0.9979\n",
      "Epoch 101/256\n",
      "15439/15439 [==============================] - 7s 471us/step - loss: 0.0241 - accuracy: 0.9979\n",
      "Epoch 102/256\n",
      "15439/15439 [==============================] - 7s 472us/step - loss: 0.0242 - accuracy: 0.9979\n",
      "Epoch 103/256\n",
      "15439/15439 [==============================] - 7s 452us/step - loss: 0.0243 - accuracy: 0.9979\n",
      "Epoch 104/256\n",
      "15439/15439 [==============================] - 7s 448us/step - loss: 0.0243 - accuracy: 0.9979\n",
      "Epoch 105/256\n",
      "15439/15439 [==============================] - 7s 464us/step - loss: 0.0244 - accuracy: 0.9979\n",
      "Epoch 106/256\n",
      "15439/15439 [==============================] - 7s 478us/step - loss: 0.0244 - accuracy: 0.9979\n",
      "Epoch 107/256\n",
      "15439/15439 [==============================] - 7s 461us/step - loss: 0.0245 - accuracy: 0.9979\n",
      "Epoch 108/256\n",
      "15439/15439 [==============================] - 7s 447us/step - loss: 0.0245 - accuracy: 0.9979\n",
      "Epoch 109/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0246 - accuracy: 0.9980\n",
      "Epoch 110/256\n",
      "15439/15439 [==============================] - 8s 486us/step - loss: 0.0247 - accuracy: 0.99800s - loss: 0.0248 - accura\n",
      "Epoch 111/256\n",
      "15439/15439 [==============================] - 8s 495us/step - loss: 0.0248 - accuracy: 0.9979\n",
      "Epoch 112/256\n",
      "15439/15439 [==============================] - 7s 474us/step - loss: 0.0248 - accuracy: 0.9980\n",
      "Epoch 113/256\n",
      "15439/15439 [==============================] - 7s 440us/step - loss: 0.0249 - accuracy: 0.9979\n",
      "Epoch 114/256\n",
      "15439/15439 [==============================] - 7s 448us/step - loss: 0.0249 - accuracy: 0.9979\n",
      "Epoch 115/256\n",
      "15439/15439 [==============================] - 7s 483us/step - loss: 0.0250 - accuracy: 0.9980\n",
      "Epoch 116/256\n",
      "15439/15439 [==============================] - 7s 435us/step - loss: 0.0250 - accuracy: 0.9980\n",
      "Epoch 117/256\n",
      "15439/15439 [==============================] - 7s 473us/step - loss: 0.0251 - accuracy: 0.9980\n",
      "Epoch 118/256\n",
      "15439/15439 [==============================] - 9s 559us/step - loss: 0.0251 - accuracy: 0.9980\n",
      "Epoch 119/256\n",
      "15439/15439 [==============================] - 8s 498us/step - loss: 0.0251 - accuracy: 0.9980\n",
      "Epoch 120/256\n",
      "15439/15439 [==============================] - 8s 522us/step - loss: 0.0252 - accuracy: 0.9980\n",
      "Epoch 121/256\n",
      "15439/15439 [==============================] - 8s 525us/step - loss: 0.0252 - accuracy: 0.9980\n",
      "Epoch 122/256\n",
      "15439/15439 [==============================] - 8s 512us/step - loss: 0.0253 - accuracy: 0.9980\n",
      "Epoch 123/256\n",
      "15439/15439 [==============================] - 7s 472us/step - loss: 0.0254 - accuracy: 0.9980\n",
      "Epoch 124/256\n",
      "15439/15439 [==============================] - 8s 498us/step - loss: 0.0254 - accuracy: 0.9980\n",
      "Epoch 125/256\n",
      "15439/15439 [==============================] - 8s 487us/step - loss: 0.0255 - accuracy: 0.9980\n",
      "Epoch 126/256\n",
      "15439/15439 [==============================] - 8s 495us/step - loss: 0.0256 - accuracy: 0.9980\n",
      "Epoch 127/256\n",
      "15439/15439 [==============================] - 7s 478us/step - loss: 0.0256 - accuracy: 0.9980\n",
      "Epoch 128/256\n",
      "15439/15439 [==============================] - 7s 479us/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 129/256\n",
      "15439/15439 [==============================] - 7s 468us/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 130/256\n",
      "15439/15439 [==============================] - 7s 474us/step - loss: 0.0257 - accuracy: 0.9980\n",
      "Epoch 131/256\n",
      "15439/15439 [==============================] - 7s 453us/step - loss: 0.0258 - accuracy: 0.9980\n",
      "Epoch 132/256\n",
      "15439/15439 [==============================] - 7s 465us/step - loss: 0.0258 - accuracy: 0.9980\n",
      "Epoch 133/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0259 - accuracy: 0.9980\n",
      "Epoch 134/256\n",
      "15439/15439 [==============================] - 7s 453us/step - loss: 0.0259 - accuracy: 0.9980\n",
      "Epoch 135/256\n",
      "15439/15439 [==============================] - 7s 484us/step - loss: 0.0260 - accuracy: 0.9980\n",
      "Epoch 136/256\n",
      "15439/15439 [==============================] - 7s 470us/step - loss: 0.0260 - accuracy: 0.9980\n",
      "Epoch 137/256\n",
      "15439/15439 [==============================] - 7s 472us/step - loss: 0.0261 - accuracy: 0.9980\n",
      "Epoch 138/256\n",
      "15439/15439 [==============================] - 8s 493us/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 139/256\n",
      "15439/15439 [==============================] - 7s 480us/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 140/256\n",
      "15439/15439 [==============================] - 8s 487us/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 141/256\n",
      "15439/15439 [==============================] - 7s 470us/step - loss: 0.0262 - accuracy: 0.9980\n",
      "Epoch 142/256\n",
      "15439/15439 [==============================] - 7s 462us/step - loss: 0.0263 - accuracy: 0.9980\n",
      "Epoch 143/256\n",
      "15439/15439 [==============================] - 7s 463us/step - loss: 0.0263 - accuracy: 0.9980\n",
      "Epoch 144/256\n",
      "15439/15439 [==============================] - 7s 463us/step - loss: 0.0264 - accuracy: 0.9980\n",
      "Epoch 145/256\n",
      "15439/15439 [==============================] - 7s 472us/step - loss: 0.0264 - accuracy: 0.9980\n",
      "Epoch 146/256\n",
      "15439/15439 [==============================] - 8s 492us/step - loss: 0.0265 - accuracy: 0.9980\n",
      "Epoch 147/256\n",
      "15439/15439 [==============================] - 7s 483us/step - loss: 0.0265 - accuracy: 0.9980\n",
      "Epoch 148/256\n",
      "15439/15439 [==============================] - 7s 483us/step - loss: 0.0266 - accuracy: 0.9980\n",
      "Epoch 149/256\n",
      "15439/15439 [==============================] - 7s 483us/step - loss: 0.0266 - accuracy: 0.9980\n",
      "Epoch 150/256\n",
      "15439/15439 [==============================] - 7s 475us/step - loss: 0.0267 - accuracy: 0.9980\n",
      "Epoch 151/256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15439/15439 [==============================] - 7s 479us/step - loss: 0.0267 - accuracy: 0.9980\n",
      "Epoch 152/256\n",
      "15439/15439 [==============================] - 7s 465us/step - loss: 0.0268 - accuracy: 0.9980\n",
      "Epoch 153/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0268 - accuracy: 0.9980\n",
      "Epoch 154/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0269 - accuracy: 0.9980\n",
      "Epoch 155/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0269 - accuracy: 0.9980\n",
      "Epoch 156/256\n",
      "15439/15439 [==============================] - 7s 485us/step - loss: 0.0269 - accuracy: 0.9980\n",
      "Epoch 157/256\n",
      "15439/15439 [==============================] - 7s 476us/step - loss: 0.0270 - accuracy: 0.9980\n",
      "Epoch 158/256\n",
      "15439/15439 [==============================] - 8s 534us/step - loss: 0.0270 - accuracy: 0.9980\n",
      "Epoch 159/256\n",
      "15439/15439 [==============================] - 8s 504us/step - loss: 0.0271 - accuracy: 0.9980\n",
      "Epoch 160/256\n",
      "15439/15439 [==============================] - 7s 483us/step - loss: 0.0271 - accuracy: 0.9980\n",
      "Epoch 161/256\n",
      "15439/15439 [==============================] - 7s 468us/step - loss: 0.0272 - accuracy: 0.9980\n",
      "Epoch 162/256\n",
      "15439/15439 [==============================] - 7s 433us/step - loss: 0.0272 - accuracy: 0.9980\n",
      "Epoch 163/256\n",
      "15439/15439 [==============================] - 7s 442us/step - loss: 0.0272 - accuracy: 0.9980\n",
      "Epoch 164/256\n",
      "15439/15439 [==============================] - 7s 433us/step - loss: 0.0272 - accuracy: 0.9980\n",
      "Epoch 165/256\n",
      "15439/15439 [==============================] - 7s 437us/step - loss: 0.0273 - accuracy: 0.9980\n",
      "Epoch 166/256\n",
      "15439/15439 [==============================] - 7s 438us/step - loss: 0.0273 - accuracy: 0.9980\n",
      "Epoch 167/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0273 - accuracy: 0.9980\n",
      "Epoch 168/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0274 - accuracy: 0.9980\n",
      "Epoch 169/256\n",
      "15439/15439 [==============================] - 7s 437us/step - loss: 0.0274 - accuracy: 0.9980\n",
      "Epoch 170/256\n",
      "15439/15439 [==============================] - 7s 429us/step - loss: 0.0275 - accuracy: 0.9980\n",
      "Epoch 171/256\n",
      "15439/15439 [==============================] - 7s 438us/step - loss: 0.0275 - accuracy: 0.9980\n",
      "Epoch 172/256\n",
      "15439/15439 [==============================] - 7s 434us/step - loss: 0.0275 - accuracy: 0.9980\n",
      "Epoch 173/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0276 - accuracy: 0.9980\n",
      "Epoch 174/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0276 - accuracy: 0.9980\n",
      "Epoch 175/256\n",
      "15439/15439 [==============================] - 7s 438us/step - loss: 0.0276 - accuracy: 0.9980\n",
      "Epoch 176/256\n",
      "15439/15439 [==============================] - 7s 432us/step - loss: 0.0277 - accuracy: 0.9980\n",
      "Epoch 177/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0277 - accuracy: 0.9980\n",
      "Epoch 178/256\n",
      "15439/15439 [==============================] - 7s 442us/step - loss: 0.0277 - accuracy: 0.9980\n",
      "Epoch 179/256\n",
      "15439/15439 [==============================] - 7s 437us/step - loss: 0.0277 - accuracy: 0.9980\n",
      "Epoch 180/256\n",
      "15439/15439 [==============================] - 7s 430us/step - loss: 0.0278 - accuracy: 0.9980\n",
      "Epoch 181/256\n",
      "15439/15439 [==============================] - 7s 440us/step - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 182/256\n",
      "15439/15439 [==============================] - 7s 442us/step - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 183/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 184/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0279 - accuracy: 0.9980\n",
      "Epoch 185/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0280 - accuracy: 0.9980\n",
      "Epoch 186/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0281 - accuracy: 0.9980\n",
      "Epoch 187/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0281 - accuracy: 0.9980\n",
      "Epoch 188/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0282 - accuracy: 0.9980\n",
      "Epoch 189/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0282 - accuracy: 0.9980\n",
      "Epoch 190/256\n",
      "15439/15439 [==============================] - 7s 447us/step - loss: 0.0283 - accuracy: 0.9980\n",
      "Epoch 191/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0283 - accuracy: 0.9980\n",
      "Epoch 192/256\n",
      "15439/15439 [==============================] - 8s 510us/step - loss: 0.0283 - accuracy: 0.9980\n",
      "Epoch 193/256\n",
      "15439/15439 [==============================] - 7s 469us/step - loss: 0.0284 - accuracy: 0.9980\n",
      "Epoch 194/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0284 - accuracy: 0.9980\n",
      "Epoch 195/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0285 - accuracy: 0.9980\n",
      "Epoch 196/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0285 - accuracy: 0.9980\n",
      "Epoch 197/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0286 - accuracy: 0.9980\n",
      "Epoch 198/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0286 - accuracy: 0.9980\n",
      "Epoch 199/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0287 - accuracy: 0.9980\n",
      "Epoch 200/256\n",
      "15439/15439 [==============================] - 7s 451us/step - loss: 0.0287 - accuracy: 0.9980\n",
      "Epoch 201/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0288 - accuracy: 0.9981\n",
      "Epoch 202/256\n",
      "15439/15439 [==============================] - 7s 433us/step - loss: 0.0288 - accuracy: 0.9980\n",
      "Epoch 203/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0289 - accuracy: 0.9981\n",
      "Epoch 204/256\n",
      "15439/15439 [==============================] - 7s 462us/step - loss: 0.0289 - accuracy: 0.9981\n",
      "Epoch 205/256\n",
      "15439/15439 [==============================] - 7s 442us/step - loss: 0.0290 - accuracy: 0.9980\n",
      "Epoch 206/256\n",
      "15439/15439 [==============================] - 7s 451us/step - loss: 0.0290 - accuracy: 0.9981\n",
      "Epoch 207/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0291 - accuracy: 0.9981\n",
      "Epoch 208/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0292 - accuracy: 0.9980\n",
      "Epoch 209/256\n",
      "15439/15439 [==============================] - 7s 456us/step - loss: 0.0292 - accuracy: 0.9980\n",
      "Epoch 210/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0293 - accuracy: 0.9981\n",
      "Epoch 211/256\n",
      "15439/15439 [==============================] - 7s 480us/step - loss: 0.0293 - accuracy: 0.9981\n",
      "Epoch 212/256\n",
      "15439/15439 [==============================] - 8s 489us/step - loss: 0.0294 - accuracy: 0.9980\n",
      "Epoch 213/256\n",
      "15439/15439 [==============================] - 7s 469us/step - loss: 0.0294 - accuracy: 0.9980\n",
      "Epoch 214/256\n",
      "15439/15439 [==============================] - 7s 463us/step - loss: 0.0295 - accuracy: 0.9981\n",
      "Epoch 215/256\n",
      "15439/15439 [==============================] - 7s 447us/step - loss: 0.0295 - accuracy: 0.9981\n",
      "Epoch 216/256\n",
      "15439/15439 [==============================] - 7s 455us/step - loss: 0.0296 - accuracy: 0.9981\n",
      "Epoch 217/256\n",
      "15439/15439 [==============================] - 7s 451us/step - loss: 0.0296 - accuracy: 0.9981\n",
      "Epoch 218/256\n",
      "15439/15439 [==============================] - 7s 449us/step - loss: 0.0297 - accuracy: 0.9981\n",
      "Epoch 219/256\n",
      "15439/15439 [==============================] - 7s 457us/step - loss: 0.0298 - accuracy: 0.9981\n",
      "Epoch 220/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0298 - accuracy: 0.9981\n",
      "Epoch 221/256\n",
      "15439/15439 [==============================] - 7s 449us/step - loss: 0.0299 - accuracy: 0.9981\n",
      "Epoch 222/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0299 - accuracy: 0.9981\n",
      "Epoch 223/256\n",
      "15439/15439 [==============================] - 7s 448us/step - loss: 0.0300 - accuracy: 0.9981\n",
      "Epoch 224/256\n",
      "15439/15439 [==============================] - 7s 449us/step - loss: 0.0300 - accuracy: 0.9981\n",
      "Epoch 225/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0301 - accuracy: 0.9981\n",
      "Epoch 226/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0301 - accuracy: 0.9981\n",
      "Epoch 227/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0302 - accuracy: 0.9981\n",
      "Epoch 228/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0303 - accuracy: 0.9981\n",
      "Epoch 229/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0303 - accuracy: 0.9981\n",
      "Epoch 230/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0304 - accuracy: 0.9981\n",
      "Epoch 231/256\n",
      "15439/15439 [==============================] - 7s 441us/step - loss: 0.0304 - accuracy: 0.9981\n",
      "Epoch 232/256\n",
      "15439/15439 [==============================] - 7s 441us/step - loss: 0.0305 - accuracy: 0.9981\n",
      "Epoch 233/256\n",
      "15439/15439 [==============================] - 7s 440us/step - loss: 0.0305 - accuracy: 0.9981\n",
      "Epoch 234/256\n",
      "15439/15439 [==============================] - 7s 436us/step - loss: 0.0305 - accuracy: 0.9981\n",
      "Epoch 235/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0307 - accuracy: 0.9981\n",
      "Epoch 236/256\n",
      "15439/15439 [==============================] - 7s 450us/step - loss: 0.0307 - accuracy: 0.9981\n",
      "Epoch 237/256\n",
      "15439/15439 [==============================] - 7s 449us/step - loss: 0.0308 - accuracy: 0.9981\n",
      "Epoch 238/256\n",
      "15439/15439 [==============================] - 7s 452us/step - loss: 0.0308 - accuracy: 0.9981\n",
      "Epoch 239/256\n",
      "15439/15439 [==============================] - 7s 448us/step - loss: 0.0309 - accuracy: 0.9981\n",
      "Epoch 240/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0309 - accuracy: 0.9981\n",
      "Epoch 241/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0310 - accuracy: 0.9981\n",
      "Epoch 242/256\n",
      "15439/15439 [==============================] - 7s 445us/step - loss: 0.0310 - accuracy: 0.9981\n",
      "Epoch 243/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0311 - accuracy: 0.9981\n",
      "Epoch 244/256\n",
      "15439/15439 [==============================] - 7s 432us/step - loss: 0.0311 - accuracy: 0.9981\n",
      "Epoch 245/256\n",
      "15439/15439 [==============================] - 7s 430us/step - loss: 0.0312 - accuracy: 0.9981\n",
      "Epoch 246/256\n",
      "15439/15439 [==============================] - 7s 446us/step - loss: 0.0312 - accuracy: 0.9981\n",
      "Epoch 247/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0313 - accuracy: 0.9981\n",
      "Epoch 248/256\n",
      "15439/15439 [==============================] - 7s 434us/step - loss: 0.0314 - accuracy: 0.9981\n",
      "Epoch 249/256\n",
      "15439/15439 [==============================] - 7s 435us/step - loss: 0.0314 - accuracy: 0.9981\n",
      "Epoch 250/256\n",
      "15439/15439 [==============================] - 7s 436us/step - loss: 0.0315 - accuracy: 0.9981\n",
      "Epoch 251/256\n",
      "15439/15439 [==============================] - 7s 431us/step - loss: 0.0315 - accuracy: 0.9981\n",
      "Epoch 252/256\n",
      "15439/15439 [==============================] - 7s 429us/step - loss: 0.0316 - accuracy: 0.9981\n",
      "Epoch 253/256\n",
      "15439/15439 [==============================] - 7s 454us/step - loss: 0.0316 - accuracy: 0.9981\n",
      "Epoch 254/256\n",
      "15439/15439 [==============================] - 7s 439us/step - loss: 0.0317 - accuracy: 0.9981\n",
      "Epoch 255/256\n",
      "15439/15439 [==============================] - 7s 443us/step - loss: 0.0318 - accuracy: 0.9981\n",
      "Epoch 256/256\n",
      "15439/15439 [==============================] - 7s 444us/step - loss: 0.0318 - accuracy: 0.9981\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24db22f7f70>"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.compile(loss='binary_crossentropy', optimizer = 'rmsprop', metrics=['accuracy'])\n",
    "model_1.fit(X_numpy, Y_numpy, epochs = 256, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d449a2b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_25 (Dense)             (None, 1)                 120       \n",
      "=================================================================\n",
      "Total params: 120\n",
      "Trainable params: 120\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5440ba5",
   "metadata": {},
   "source": [
    "Conlusion-1:\n",
    "\n",
    "As seen from the above model, the basic logistic regression model has achieved an accuracy of 99.81 with 256 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26cb6e5",
   "metadata": {},
   "source": [
    "#### Step-2 : Model with more layers and neurons so that dataset can overfit to 100%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ffcb949",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = Sequential()\n",
    "model_2.add(Dense(8, input_dim = len(X_numpy[0, :]), activation='relu'))\n",
    "model_2.add(Dense(4, activation='relu'))\n",
    "model_2.add(Dense(2, activation='relu'))\n",
    "model_2.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75792d41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "15439/15439 [==============================] - 9s 542us/step - loss: 0.0032 - accuracy: 0.9993\n",
      "Epoch 2/32\n",
      "15439/15439 [==============================] - 8s 540us/step - loss: 0.0027 - accuracy: 0.9994\n",
      "Epoch 3/32\n",
      "15439/15439 [==============================] - 8s 540us/step - loss: 0.0025 - accuracy: 0.9994\n",
      "Epoch 4/32\n",
      "15439/15439 [==============================] - 8s 537us/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 5/32\n",
      "15439/15439 [==============================] - 8s 544us/step - loss: 0.0022 - accuracy: 0.9995\n",
      "Epoch 6/32\n",
      "15439/15439 [==============================] - 8s 537us/step - loss: 0.0021 - accuracy: 0.9995\n",
      "Epoch 7/32\n",
      "15439/15439 [==============================] - 8s 537us/step - loss: 0.0020 - accuracy: 0.9995\n",
      "Epoch 8/32\n",
      "15439/15439 [==============================] - 9s 551us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 9/32\n",
      "15439/15439 [==============================] - 8s 546us/step - loss: 0.0019 - accuracy: 0.9995\n",
      "Epoch 10/32\n",
      "15439/15439 [==============================] - 9s 573us/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 11/32\n",
      "15439/15439 [==============================] - 9s 554us/step - loss: 0.0018 - accuracy: 0.9996\n",
      "Epoch 12/32\n",
      "15439/15439 [==============================] - 9s 564us/step - loss: 0.0018 - accuracy: 0.9995\n",
      "Epoch 13/32\n",
      "15439/15439 [==============================] - 9s 576us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 14/32\n",
      "15439/15439 [==============================] - 9s 571us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 15/32\n",
      "15439/15439 [==============================] - 9s 574us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 16/32\n",
      "15439/15439 [==============================] - 9s 563us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 17/32\n",
      "15439/15439 [==============================] - 9s 557us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 18/32\n",
      "15439/15439 [==============================] - 9s 555us/step - loss: 0.0017 - accuracy: 0.9996\n",
      "Epoch 19/32\n",
      "15439/15439 [==============================] - 9s 567us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 20/32\n",
      "15439/15439 [==============================] - 9s 557us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 21/32\n",
      "15439/15439 [==============================] - 9s 564us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 22/32\n",
      "15439/15439 [==============================] - 9s 564us/step - loss: 0.0016 - accuracy: 0.9996\n",
      "Epoch 23/32\n",
      "15439/15439 [==============================] - 9s 552us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 24/32\n",
      "15439/15439 [==============================] - 9s 555us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 25/32\n",
      "15439/15439 [==============================] - 9s 567us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 26/32\n",
      "15439/15439 [==============================] - 9s 610us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 27/32\n",
      "15439/15439 [==============================] - 9s 555us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 28/32\n",
      "15439/15439 [==============================] - 9s 556us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 29/32\n",
      "15439/15439 [==============================] - 8s 550us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 30/32\n",
      "15439/15439 [==============================] - 8s 548us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 31/32\n",
      "15439/15439 [==============================] - 9s 554us/step - loss: 0.0015 - accuracy: 0.9996\n",
      "Epoch 32/32\n",
      "15439/15439 [==============================] - 9s 552us/step - loss: 0.0015 - accuracy: 0.9996\n"
     ]
    }
   ],
   "source": [
    "model_2.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])\n",
    "model_2_history = model_2.fit(X_numpy, Y_numpy, epochs = 32, verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb3872b",
   "metadata": {},
   "source": [
    "##### Model - 2: Epochs vs Loss & Epochs vs Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e09a704e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(model_2_history.history['accuracy'])\n",
    "plt.title('model 2: accuracy vs epochs')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(model_2_history.history['loss'])\n",
    "plt.title('model 2: loss vs epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "db025b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 8)                 960       \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 4)                 36        \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 2)                 10        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 1,009\n",
      "Trainable params: 1,009\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25332521",
   "metadata": {},
   "source": [
    "Conclusion-2: A seen from the model-2 performance we have achieved 99.96% accuracy (close to 100%) which means this model did overfit the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
